{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.0 Problem Statement\n",
    "#### ZERO-IN ON IMPACT OF MARKDOWNS\n",
    "\n",
    "In this section, we will be implementing Gaussian Naive Bayes Classifier in python to the impact of the **MarkDowns** on **Clearance_Clothings [Clothings on sales]**.\n",
    "\n",
    "Bayes’ theorem is based on conditional probability. The conditional probability helps us in calculating the probability that something will happen, given that something else has already happened. The Naive Bayes classifier works using the Bayes theorem. It assumes all the features are independent to each other. Even if the features depend on each other or upon the existence of the other features, Naive Bayes classifier considers all of these properties to independently contribute to the probability that the target event occurs.\n",
    "\n",
    "### 16.1 Gaussian Naive Bayes\n",
    "A Gaussian Naive Bayes algorithm is a special type of Naive Bayes (NB) algorithm. It’s specifically used when the features have continuous values. It’s also assumed that all the features are following a gaussian distribution i.e, normal distribution.\n",
    "\n",
    "\n",
    "\n",
    "### 16.2 The Dataset\n",
    "The dataset for this analysis will be extracted from the master retail sales dataset. The five markdowns will be used to predict whether the clearance clothing sales is **Weak** <=10k (0), **Average** (>10K -greater than 10K) or <=20k (1), **Strong** (>20K -greater than 20K) or <=30k (2), or **very Strong** (>30K - greater than 30K) (3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.3 Import required Python machine learning packages\n",
    "We need to import pandas, numpy and sklearn libraries. From sklearn, we need to import preprocessing modules like Imputer. The Imputer package helps to impute the missing values (NB: Missing values have already been taken care of in our master dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angus\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Required Python Machine learning Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For preprocessing the data\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import preprocessing\n",
    "# To split the dataset into train and test datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# To model the Gaussian Navie Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# To calculate the accuracy score of the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above python machine learning packages we are going to use to build the random forest classifier. Let’s talk about the need for these packages in random forest classifier implementation.\n",
    "\n",
    "The train_test_split module is for splitting the dataset into training and testing set. The accuracy_score module will be used for calculating the accuracy of our Gaussian Naive Bayes algorithm.\n",
    "\n",
    "### 16.4 Data Importing\n",
    "For importing the data and manipulating it, we are going to use pandas dataframes. First of all, we will download the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the file 'master_dataset.xlsx' into a DataFrame df using the read_xls() function.\n",
    "df = pd.read_excel('master_dataset.xlsx', sheetname='Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are saving our data into “df” dataframe. For checking the length & dimensions of our dataframe, we can use len() method & “.shape” and for checking the features names and information about the data set, we use .keys and .info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8190 entries, 0 to 8189\n",
      "Data columns (total 95 columns):\n",
      "Store                     8190 non-null int64\n",
      "Date                      8190 non-null datetime64[ns]\n",
      "Temperature               8190 non-null float64\n",
      "Fuel_Price                8190 non-null float64\n",
      "MarkDown1                 8190 non-null float64\n",
      "MarkDown2                 8190 non-null float64\n",
      "MarkDown3                 8190 non-null float64\n",
      "MarkDown4                 8190 non-null float64\n",
      "MarkDown5                 8190 non-null float64\n",
      "CPI                       8190 non-null float64\n",
      "Unemployment              8190 non-null float64\n",
      "IsHoliday                 8190 non-null bool\n",
      "Type                      8190 non-null object\n",
      "Size                      8190 non-null int64\n",
      "Jewelry                   8190 non-null float64\n",
      "Pets                      8190 non-null float64\n",
      "TV_Video                  8190 non-null float64\n",
      "Cell_Phones               8190 non-null float64\n",
      "Pharmaceutical            8190 non-null float64\n",
      "Health_beauty             8190 non-null float64\n",
      "Toy                       8190 non-null float64\n",
      "Home_others               8190 non-null float64\n",
      "Kitchen                   8190 non-null float64\n",
      "Bedding                   8190 non-null float64\n",
      "Bathroom                  8190 non-null float64\n",
      "Office_supplies           8190 non-null float64\n",
      "School_Supplies           8190 non-null float64\n",
      "Home_Office               8190 non-null float64\n",
      "Craft_general             8190 non-null float64\n",
      "Floral                    8190 non-null float64\n",
      "Beading                   8190 non-null float64\n",
      "Paint                     8190 non-null float64\n",
      "Framing                   8190 non-null float64\n",
      "outdoor                   8190 non-null float64\n",
      "Auto                      8190 non-null float64\n",
      "School_Uniforms           8190 non-null float64\n",
      "Baby_Toddlers_Clothing    8190 non-null float64\n",
      "Baby_Kids_Shoes           8190 non-null float64\n",
      "Clearance_Clothings       8190 non-null float64\n",
      "Boys_Clothing             8190 non-null float64\n",
      "Girls_Clothing            8190 non-null float64\n",
      "Women_Clothing            8190 non-null float64\n",
      "Intimates_Sleepwears      8190 non-null float64\n",
      "Men_Clothings             8190 non-null float64\n",
      "Precious_Metals           8190 non-null float64\n",
      "Active_Wear               8190 non-null float64\n",
      "Adult_Shoes               8190 non-null float64\n",
      "Bags_Accessories          8190 non-null float64\n",
      "Sportswear                8190 non-null float64\n",
      "Computer                  8190 non-null float64\n",
      "Music                     8190 non-null float64\n",
      "Luggage                   8190 non-null float64\n",
      "Food                      8190 non-null float64\n",
      "Fruit                     8190 non-null float64\n",
      "Grocery                   8190 non-null float64\n",
      "Laundry                   8190 non-null float64\n",
      "IPad_Tablets              8190 non-null float64\n",
      "Heating_Cooling           8190 non-null float64\n",
      "Swim_Shop                 8190 non-null float64\n",
      "Gift_cards                8190 non-null float64\n",
      "Baby_Essentials           8190 non-null float64\n",
      "Cribs                     8190 non-null float64\n",
      "Car_Seats                 8190 non-null float64\n",
      "Strollers                 8190 non-null float64\n",
      "Bikes                     8190 non-null float64\n",
      "Photo                     8190 non-null float64\n",
      "Household_Essentials      8190 non-null float64\n",
      "Air_Quality               8190 non-null float64\n",
      "Light_bulbs               8190 non-null float64\n",
      "Gardening                 8190 non-null float64\n",
      "Building_Materials        8190 non-null float64\n",
      "Hardware                  8190 non-null float64\n",
      "Electrical                8190 non-null float64\n",
      "Home_Safety               8190 non-null float64\n",
      "Tools                     8190 non-null float64\n",
      "Teen_Room                 8190 non-null float64\n",
      "Kids_Room                 8190 non-null float64\n",
      "Lighting                  8190 non-null float64\n",
      "Home_Decor                8190 non-null float64\n",
      "Mattresses                8190 non-null float64\n",
      "Furniture                 8190 non-null float64\n",
      "Storage                   8190 non-null float64\n",
      "Appliances                8190 non-null float64\n",
      "Pioneer_Woman             8190 non-null float64\n",
      "Computer_Software         8190 non-null float64\n",
      "Books                     8190 non-null float64\n",
      "Musical_Instruments       8190 non-null float64\n",
      "Star_Wars                 8190 non-null float64\n",
      "Movies_TV                 8190 non-null float64\n",
      "Video_Games               8190 non-null float64\n",
      "Portable_Audios           8190 non-null float64\n",
      "Cameras_Camcoders         8190 non-null float64\n",
      "Auto_Electronics          8190 non-null float64\n",
      "Wearable_Tech             8190 non-null float64\n",
      "Smart_homes               8190 non-null float64\n",
      "dtypes: bool(1), datetime64[ns](1), float64(90), int64(2), object(1)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16.4.1 The MarkDowns\n",
    "One of the key interests in our dataset are the markdowns. There are five markdowns: Markdown1 (Promotions carried out from Easter (Spring), MarkDown2 (Promotions carried out from thanksgiving), MarkDown3 (Promotions carried out from Christmas), MarkDown4 (Promotions carried out from Labor Day) and Markdown5 (Promotions carried out from Summer). \n",
    "\n",
    "We will extract the features and assign a name markdown_df to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create markdown dataset\n",
    "markdown_df = df[['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10382.9</td>\n",
       "      <td>6115.67</td>\n",
       "      <td>215.07</td>\n",
       "      <td>2406.62</td>\n",
       "      <td>6551.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10382.9</td>\n",
       "      <td>6115.67</td>\n",
       "      <td>215.07</td>\n",
       "      <td>2406.62</td>\n",
       "      <td>6551.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10382.9</td>\n",
       "      <td>6115.67</td>\n",
       "      <td>215.07</td>\n",
       "      <td>2406.62</td>\n",
       "      <td>6551.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10382.9</td>\n",
       "      <td>6115.67</td>\n",
       "      <td>215.07</td>\n",
       "      <td>2406.62</td>\n",
       "      <td>6551.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10382.9</td>\n",
       "      <td>6115.67</td>\n",
       "      <td>215.07</td>\n",
       "      <td>2406.62</td>\n",
       "      <td>6551.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5\n",
       "0    10382.9    6115.67     215.07    2406.62    6551.42\n",
       "1    10382.9    6115.67     215.07    2406.62    6551.42\n",
       "2    10382.9    6115.67     215.07    2406.62    6551.42\n",
       "3    10382.9    6115.67     215.07    2406.62    6551.42\n",
       "4    10382.9    6115.67     215.07    2406.62    6551.42"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the first five rows of the markdown dataset\\\n",
    "markdown_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16.4.2 Clearance Clothing Sales\n",
    "Clearance clothing sales will be used as the target variable. The sales ranges from 0 weekly sales to 40,000 weekly sales. Therefore, we have divided the weekly sales to into four categories:\n",
    "\n",
    "0 - Weak - Sales below or equal to 10k\n",
    "1 - Average - Sales between 10k and 20k (including 20k)\n",
    "2 - Strong - Sales between 20k and 30k (including 30k)\n",
    "4 - Very Strong - Sales above 30k\n",
    "\n",
    "Let us create a target column from the existing Clearance Clothing Sales column and assign the name df['range'] to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store       Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  \\\n",
      "0      1 2010-05-02        42.31       2.572    10382.9    6115.67     215.07   \n",
      "1      1 2010-12-02        38.51       2.548    10382.9    6115.67     215.07   \n",
      "2      1 2010-02-19        39.93       2.514    10382.9    6115.67     215.07   \n",
      "3      1 2010-02-26        46.63       2.561    10382.9    6115.67     215.07   \n",
      "4      1 2010-05-03        46.50       2.625    10382.9    6115.67     215.07   \n",
      "\n",
      "   MarkDown4  MarkDown5         CPI   ...     Musical_Instruments  Star_Wars  \\\n",
      "0    2406.62    6551.42  211.096358   ...                57022.45  118966.90   \n",
      "1    2406.62    6551.42  211.242170   ...                57845.36  126907.41   \n",
      "2    2406.62    6551.42  211.289143   ...                59462.22  122267.65   \n",
      "3    2406.62    6551.42  211.319643   ...                63011.44  135066.75   \n",
      "4    2406.62    6551.42  211.350143   ...                57335.17  125048.08   \n",
      "\n",
      "  Movies_TV  Video_Games  Portable_Audios  Cameras_Camcoders  \\\n",
      "0  58034.24     56157.83        113009.41           27930.71   \n",
      "1  63245.00     66172.11        111466.37            5265.09   \n",
      "2  69962.56     62795.87        124821.44            5265.09   \n",
      "3  62581.64     72212.32        107952.07           28420.73   \n",
      "4  57630.02     55501.07        103652.58           28420.73   \n",
      "\n",
      "   Auto_Electronics  Wearable_Tech  Smart_homes    range  \n",
      "0          32954.82       10344.16         0.01     Weak  \n",
      "1          30149.20       14740.14         0.01     Weak  \n",
      "2          33726.13       10139.42         0.01     Weak  \n",
      "3          31585.78       12087.95        20.00  Average  \n",
      "4          28457.31       10871.74        20.00     Weak  \n",
      "\n",
      "[5 rows x 96 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create new column for the different categories of clearance clothing\n",
    "\n",
    "conditions = [\n",
    "    (df['Clearance_Clothings'] <= 10000),\n",
    "    (df['Clearance_Clothings']> 10000) & (df['Clearance_Clothings'] <= 20000),\n",
    "    (df['Clearance_Clothings']> 20000) & (df['Clearance_Clothings'] <= 30000),\n",
    "    (df['Clearance_Clothings']> 30000)]\n",
    "choices = ['Weak', 'Average', 'Strong', 'Very Strong']\n",
    "df['range'] = np.select(conditions, choices, default='Normal')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create master dataset for analysis - assign the name clearance_df to it\n",
    "clearance_df = df[['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'range']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10382.9</td>\n",
       "      <td>6115.67</td>\n",
       "      <td>215.07</td>\n",
       "      <td>2406.62</td>\n",
       "      <td>6551.42</td>\n",
       "      <td>Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10382.9</td>\n",
       "      <td>6115.67</td>\n",
       "      <td>215.07</td>\n",
       "      <td>2406.62</td>\n",
       "      <td>6551.42</td>\n",
       "      <td>Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10382.9</td>\n",
       "      <td>6115.67</td>\n",
       "      <td>215.07</td>\n",
       "      <td>2406.62</td>\n",
       "      <td>6551.42</td>\n",
       "      <td>Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10382.9</td>\n",
       "      <td>6115.67</td>\n",
       "      <td>215.07</td>\n",
       "      <td>2406.62</td>\n",
       "      <td>6551.42</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10382.9</td>\n",
       "      <td>6115.67</td>\n",
       "      <td>215.07</td>\n",
       "      <td>2406.62</td>\n",
       "      <td>6551.42</td>\n",
       "      <td>Weak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5    range\n",
       "0    10382.9    6115.67     215.07    2406.62    6551.42     Weak\n",
       "1    10382.9    6115.67     215.07    2406.62    6551.42     Weak\n",
       "2    10382.9    6115.67     215.07    2406.62    6551.42     Weak\n",
       "3    10382.9    6115.67     215.07    2406.62    6551.42  Average\n",
       "4    10382.9    6115.67     215.07    2406.62    6551.42     Weak"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the first five rows of clearance_df\n",
    "clearance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.5 Data preprocessing\n",
    "\n",
    "For preprocessing, we are going to make a duplicate copy of our original dataframe. We are duplicating clearance_df to clearance_df_rev dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make a duplicate copy of clearance_df\n",
    "clearance_df_rev= clearance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, we need some summary statistics of our preprocessed dataframe. For this, we can use describe() method. It can be used to generate various summary statistics, excluding NaN values.\n",
    "\n",
    "We are passing an “include” parameter with value as “all”, this is used to specify that we want summary statistics of all the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8190.000000</td>\n",
       "      <td>8190.000000</td>\n",
       "      <td>8190.000000</td>\n",
       "      <td>8190.000000</td>\n",
       "      <td>8190.000000</td>\n",
       "      <td>8190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8887.617797</td>\n",
       "      <td>6107.224317</td>\n",
       "      <td>928.785220</td>\n",
       "      <td>3130.176556</td>\n",
       "      <td>4544.031686</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9180.062712</td>\n",
       "      <td>8960.310896</td>\n",
       "      <td>7528.138611</td>\n",
       "      <td>5183.784963</td>\n",
       "      <td>9679.725089</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2781.450000</td>\n",
       "      <td>-265.760000</td>\n",
       "      <td>-179.260000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>-185.170000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2475.847500</td>\n",
       "      <td>197.840000</td>\n",
       "      <td>14.540000</td>\n",
       "      <td>263.087500</td>\n",
       "      <td>1882.345000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7174.090000</td>\n",
       "      <td>2006.620000</td>\n",
       "      <td>117.920000</td>\n",
       "      <td>1772.815000</td>\n",
       "      <td>3508.880000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11435.142500</td>\n",
       "      <td>8716.860000</td>\n",
       "      <td>327.840000</td>\n",
       "      <td>3834.440000</td>\n",
       "      <td>5588.330000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>103184.980000</td>\n",
       "      <td>104519.540000</td>\n",
       "      <td>149483.310000</td>\n",
       "      <td>67474.850000</td>\n",
       "      <td>771448.100000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MarkDown1      MarkDown2      MarkDown3     MarkDown4  \\\n",
       "count     8190.000000    8190.000000    8190.000000   8190.000000   \n",
       "unique            NaN            NaN            NaN           NaN   \n",
       "top               NaN            NaN            NaN           NaN   \n",
       "freq              NaN            NaN            NaN           NaN   \n",
       "mean      8887.617797    6107.224317     928.785220   3130.176556   \n",
       "std       9180.062712    8960.310896    7528.138611   5183.784963   \n",
       "min      -2781.450000    -265.760000    -179.260000      0.220000   \n",
       "25%       2475.847500     197.840000      14.540000    263.087500   \n",
       "50%       7174.090000    2006.620000     117.920000   1772.815000   \n",
       "75%      11435.142500    8716.860000     327.840000   3834.440000   \n",
       "max     103184.980000  104519.540000  149483.310000  67474.850000   \n",
       "\n",
       "            MarkDown5 range  \n",
       "count     8190.000000  8190  \n",
       "unique            NaN     4  \n",
       "top               NaN  Weak  \n",
       "freq              NaN  4756  \n",
       "mean      4544.031686   NaN  \n",
       "std       9679.725089   NaN  \n",
       "min       -185.170000   NaN  \n",
       "25%       1882.345000   NaN  \n",
       "50%       3508.880000   NaN  \n",
       "75%       5588.330000   NaN  \n",
       "max     771448.100000   NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset basic statistics\n",
    "\n",
    "clearance_df_rev.describe(include= 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For naive Bayes, we need to convert all the data values in one format. We are going to encode all the labels with the value between **0** and n_classes **-1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.6 One-Hot Encoder\n",
    "For implementing this, we are going to use LabelEncoder of scikit learn library. For encoding, we can also use the One-Hot encoder. It encodes the data into binary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "MarkDown1_cat = le.fit_transform(clearance_df.MarkDown1)\n",
    "MarkDown2_cat = le.fit_transform(clearance_df.MarkDown2)\n",
    "MarkDown3_cat   = le.fit_transform(clearance_df.MarkDown3)\n",
    "MarkDown4_cat   = le.fit_transform(clearance_df.MarkDown4)\n",
    "MarkDown5_cat   = le.fit_transform(clearance_df.MarkDown5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize the encoded categorical columns\n",
    "clearance_df_rev['MarkDown1'] = MarkDown1_cat\n",
    "clearance_df_rev['MarkDown2'] = MarkDown2_cat\n",
    "clearance_df_rev['MarkDown3'] = MarkDown3_cat\n",
    "clearance_df_rev['MarkDown4'] = MarkDown4_cat\n",
    "clearance_df_rev['MarkDown5'] = MarkDown5_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>range</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weak</td>\n",
       "      <td>3226</td>\n",
       "      <td>2326</td>\n",
       "      <td>2149</td>\n",
       "      <td>2269</td>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weak</td>\n",
       "      <td>3226</td>\n",
       "      <td>2326</td>\n",
       "      <td>2149</td>\n",
       "      <td>2269</td>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weak</td>\n",
       "      <td>3226</td>\n",
       "      <td>2326</td>\n",
       "      <td>2149</td>\n",
       "      <td>2269</td>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Average</td>\n",
       "      <td>3226</td>\n",
       "      <td>2326</td>\n",
       "      <td>2149</td>\n",
       "      <td>2269</td>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weak</td>\n",
       "      <td>3226</td>\n",
       "      <td>2326</td>\n",
       "      <td>2149</td>\n",
       "      <td>2269</td>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     range  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5\n",
       "0     Weak       3226       2326       2149       2269       3465\n",
       "1     Weak       3226       2326       2149       2269       3465\n",
       "2     Weak       3226       2326       2149       2269       3465\n",
       "3  Average       3226       2326       2149       2269       3465\n",
       "4     Weak       3226       2326       2149       2269       3465"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clearance_df_rev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new pandas dataframe from the encoded categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clearance_df_new = pd.DataFrame({'MarkDown1_cat':MarkDown1_cat, 'MarkDown2_cat':MarkDown2_cat, 'MarkDown3_cat':MarkDown3_cat,\n",
    "                                'MarkDown4_cat':MarkDown4_cat, 'MarkDown5_cat':MarkDown5_cat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MarkDown1_cat</th>\n",
       "      <th>MarkDown2_cat</th>\n",
       "      <th>MarkDown3_cat</th>\n",
       "      <th>MarkDown4_cat</th>\n",
       "      <th>MarkDown5_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3226</td>\n",
       "      <td>2326</td>\n",
       "      <td>2149</td>\n",
       "      <td>2269</td>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3226</td>\n",
       "      <td>2326</td>\n",
       "      <td>2149</td>\n",
       "      <td>2269</td>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3226</td>\n",
       "      <td>2326</td>\n",
       "      <td>2149</td>\n",
       "      <td>2269</td>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3226</td>\n",
       "      <td>2326</td>\n",
       "      <td>2149</td>\n",
       "      <td>2269</td>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3226</td>\n",
       "      <td>2326</td>\n",
       "      <td>2149</td>\n",
       "      <td>2269</td>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MarkDown1_cat  MarkDown2_cat  MarkDown3_cat  MarkDown4_cat  MarkDown5_cat\n",
       "0           3226           2326           2149           2269           3465\n",
       "1           3226           2326           2149           2269           3465\n",
       "2           3226           2326           2149           2269           3465\n",
       "3           3226           2326           2149           2269           3465\n",
       "4           3226           2326           2149           2269           3465"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the first 6 rows of clearance_df_new\n",
    "clearance_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.6 Standardization of Data\n",
    "All the data values of our dataframe are numeric. Now, we need to convert them on a single scale. We can standardize the values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Standardization of Data\n",
    "num_features = ['MarkDown1_cat', 'MarkDown2_cat', 'MarkDown3_cat', 'MarkDown4_cat', 'MarkDown5_cat']\n",
    "\n",
    "scaled_features = {}\n",
    "for each in num_features:\n",
    "    mean, std = clearance_df_new[each].mean(), clearance_df_new[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    clearance_df_new.loc[:, each] = (clearance_df_new[each] - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have converted our data values into standardized values. Let us print and check the output of dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MarkDown1_cat  MarkDown2_cat  MarkDown3_cat  MarkDown4_cat  \\\n",
      "8185      -0.200620       0.014843      -1.538562       0.482946   \n",
      "8186       0.582277       0.378397       1.129279       1.102460   \n",
      "8187      -0.439337       0.295132       0.086583      -0.419120   \n",
      "8188      -0.676483       0.041816       0.638196      -0.843903   \n",
      "8189      -1.559892      -0.062559      -1.609369      -1.613284   \n",
      "\n",
      "      MarkDown5_cat  \n",
      "8185      -0.019395  \n",
      "8186      -1.092529  \n",
      "8187      -0.602795  \n",
      "8188      -1.502871  \n",
      "8189      -0.820454  \n"
     ]
    }
   ],
   "source": [
    "print(clearance_df_new.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.7 Data Slicing\n",
    "\n",
    "Let’s split the data into training and test set. We can easily perform this step using sklearn’s train_test_split() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the dataset to training and test set\n",
    "features = clearance_df_new.values\n",
    "target = clearance_df['range'].values\n",
    "features_train, features_test, target_train, target_test = train_test_split(features,\n",
    "                                                                            target, test_size = 0.33, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Using above code snippet, we have divided the data into features and target set. The feature set consists of 5 columns i.e, predictor variables and target set consists of 1 column with class values.\n",
    "\n",
    "The features_train & target_train consists of training data and the features_test & target_test consists of testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 16.8 Gaussian Naive Bayes Implementation\n",
    "After completing the data preprocessing. it’s time to implement machine learning algorithm on it. We are going to use sklearn’s GaussianNB module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Implement GNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, target_train)\n",
    "target_pred = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built a GaussianNB classifier. The classifier is trained using training data. We can use fit() method for training it. After building a classifier, our model is ready to make predictions. We can use predict() method with test set features as its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.9 Accuracy of our Gaussian Naive Bayes model\n",
    "\n",
    "It’s time to test the quality of our model. We have made some predictions. Let’s compare the model’s prediction with actual target values for the test set. By following this method, we are going to calculate the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60858305586385497"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy_score\n",
    "accuracy_score(target_test, target_pred, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is giving an accuracy of 60%. This is not bad with a simple implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  60.8583055864\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy is \", accuracy_score(target_test, target_pred, normalize = True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
